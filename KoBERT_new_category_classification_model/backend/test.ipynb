{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7kFBBS2YbRhB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\r2com\\Desktop\\sesac4men\\backend\\.backend_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "from transformers import BertModel\n",
        "from kobert_tokenizer import KoBERTTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device_type)\n",
        "print(device)\n",
        "\n",
        "sent_key, label_key = 'document', 'label'\n",
        "\n",
        "digital = [\"internet\", \"science\", \"game\", \"it\", \"device\", \"mobile\", \"software\", \"others\"]\n",
        "society = [\"affair\", \"people\", \"education\", \"media\", \"woman\", \"welfare\", \"others\", \"labor\", \"environment\"]\n",
        "economic = [\"finance\", \"industry\", \"employ\", \"others\", \"autos\", \"stock\", \"estate\", \"consumer\", \"world\"]\n",
        "culture = [\"health\", \"life\", \"art\", \"book\", \"leisure\", \"others\", \"weather\", \"fashion\", \"home\", \"food\", \"religion\"]\n",
        "\n",
        "labels = {\"digital\": digital, \"society\": society, \"economic\": economic, \"culture\": culture}\n",
        "\n",
        "label2idx = {0: \"digital\", 1: \"society\", 2: \"economic\", 3: \"culture\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_pEiaViwdC3b"
      },
      "outputs": [],
      "source": [
        "class BERTSentenceTransform:\n",
        "\n",
        "    def __init__(self, tokenizer, max_seq_length, pad=True):\n",
        "        self._tokenizer = tokenizer\n",
        "        self._max_seq_length = max_seq_length\n",
        "        self._pad = pad\n",
        "\n",
        "    def __call__(self, sent):\n",
        "        sent_tokens = self._tokenizer.tokenize(sent)\n",
        "        if len(sent_tokens) > self._max_seq_length - 2:\n",
        "            sent_tokens = sent_tokens[0:(self._max_seq_length - 2)]\n",
        "\n",
        "        tokens = []\n",
        "        tokens.append(\"[CLS]\")\n",
        "        tokens.extend(sent_tokens)\n",
        "        tokens.append(\"[SEP]\")\n",
        "\n",
        "        segment_ids = [0] * len(tokens)\n",
        "        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n",
        "        valid_length = len(input_ids)\n",
        "\n",
        "        if self._pad:\n",
        "            padding_length = self._max_seq_length - valid_length\n",
        "            input_ids.extend([1] * padding_length)\n",
        "            segment_ids.extend([0] * padding_length)\n",
        "\n",
        "        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n",
        "            np.array(segment_ids, dtype='int32')\n",
        "    \n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes = 4,\n",
        "                 dr_rate = None,\n",
        "                 params = None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p = dr_rate)\n",
        "\n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict = False)\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8jwLO8EudgOT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
            "The class this function is called from is 'KoBERTTokenizer'.\n"
          ]
        }
      ],
      "source": [
        "config = dict(\n",
        "    max_len=100,\n",
        "    batch_size=64,\n",
        "    warmup_ratio=0.1,\n",
        "    num_epochs=3,\n",
        "    max_grad_norm=1,\n",
        "    log_interval=200,\n",
        "    learning_rate=5e-5,\n",
        ")\n",
        "\n",
        "topic_name = label2idx[3]\n",
        "topic = labels[topic_name]\n",
        "label_num = len(topic)\n",
        "\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "bertmodel = BertModel.from_pretrained(\"skt/kobert-base-v1\")\n",
        "bertmodel.to(device)\n",
        "\n",
        "model = BERTClassifier(bertmodel, dr_rate = 0.5).to(device)\n",
        "model = BERTClassifier(bertmodel, num_classes=label_num, dr_rate = 0.5).to(device)\n",
        "transform = BERTSentenceTransform(tokenizer, max_seq_length=config[\"max_len\"], pad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iwWK-uRIe66w"
      },
      "outputs": [],
      "source": [
        "def predict(predict_sentence):\n",
        "    token_ids, valid_length, segment_ids = transform(predict_sentence)\n",
        "\n",
        "    model.eval()\n",
        "    token_ids = torch.tensor([token_ids]).to(device)\n",
        "    segment_ids = torch.tensor(segment_ids).to(device)\n",
        "\n",
        "    out = model(token_ids, [valid_length], segment_ids)\n",
        "\n",
        "    prob = F.softmax(out, dim=1)[0]\n",
        "    for i in range(label_num):\n",
        "        print(f\"{topic[i]}: {prob[i] * 100:.2f}%\")\n",
        "\n",
        "    test_eval = []\n",
        "    for i in out:\n",
        "        logits = i\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "\n",
        "        test_eval.append(topic[np.argmax(logits)])\n",
        "\n",
        "    print(\">> 입력하신 기사는 \" + test_eval[0] + \" 기사입니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "health: 6.89%\n",
            "life: 9.93%\n",
            "art: 11.54%\n",
            "book: 6.36%\n",
            "leisure: 10.40%\n",
            "others: 7.74%\n",
            "weather: 5.81%\n",
            "fashion: 12.63%\n",
            "home: 11.73%\n",
            "food: 8.56%\n",
            "religion: 8.41%\n",
            ">> 입력하신 기사는 fashion 기사입니다.\n"
          ]
        }
      ],
      "source": [
        "predict(news_art)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J2ERED1MfUt-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\r2com\\AppData\\Local\\Temp\\ipykernel_16792\\2558525870.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
            "  token_ids = torch.tensor([token_ids]).to(device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "health: 8.59%\n",
            "life: 10.99%\n",
            "art: 7.99%\n",
            "book: 10.93%\n",
            "leisure: 7.89%\n",
            "others: 9.20%\n",
            "weather: 4.50%\n",
            "fashion: 8.05%\n",
            "home: 18.66%\n",
            "food: 5.49%\n",
            "religion: 7.69%\n",
            ">> 입력하신 기사는 home 기사입니다.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 질문에 0 입력 시 종료\n",
        "\n",
        "while True:\n",
        "    sentence = input(\"분류하고 싶은 기사를 입력해주세요 (종료하려면 0 입력) : \")\n",
        "    if sentence == \"0\" :\n",
        "        break\n",
        "    predict(sentence)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 1, 2, 3, 4])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([1,2,3,4])\n",
        "b = torch.tensor([1,2,3,4])\n",
        "torch.cat((a, b))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\r2com\\Desktop\\sesac4men\\backend\\.backend_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\r2com\\.cache\\huggingface\\hub\\models--uine--1kobert-article-economic-classifier. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at uine/1kobert-article-economic-classifier and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([9]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([9, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "model_path = \"uine/1kobert-article-economic-classifier\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=9,ignore_mismatched_sizes=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.bert.embeddings.word_embeddings.num_embeddings = 8002\n",
        "model.bert.embeddings.word_embeddings.padding_idx = 1\n",
        "model.dropout.p = 0.5\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['T_destination',\n",
              " '__annotations__',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_apply',\n",
              " '_assisted_decoding',\n",
              " '_auto_class',\n",
              " '_autoset_attn_implementation',\n",
              " '_backward_compatibility_gradient_checkpointing',\n",
              " '_backward_hooks',\n",
              " '_backward_pre_hooks',\n",
              " '_beam_sample',\n",
              " '_beam_search',\n",
              " '_buffers',\n",
              " '_call_impl',\n",
              " '_check_and_enable_flash_attn_2',\n",
              " '_check_and_enable_sdpa',\n",
              " '_compiled_call_impl',\n",
              " '_constrained_beam_search',\n",
              " '_contrastive_search',\n",
              " '_convert_head_mask_to_5d',\n",
              " '_copy_lm_head_original_to_resized',\n",
              " '_create_repo',\n",
              " '_dispatch_accelerate_model',\n",
              " '_expand_inputs_for_generation',\n",
              " '_extract_past_from_model_output',\n",
              " '_forward_hooks',\n",
              " '_forward_hooks_always_called',\n",
              " '_forward_hooks_with_kwargs',\n",
              " '_forward_pre_hooks',\n",
              " '_forward_pre_hooks_with_kwargs',\n",
              " '_from_config',\n",
              " '_get_backward_hooks',\n",
              " '_get_backward_pre_hooks',\n",
              " '_get_candidate_generator',\n",
              " '_get_decoder_start_token_id',\n",
              " '_get_files_timestamps',\n",
              " '_get_logits_processor',\n",
              " '_get_logits_warper',\n",
              " '_get_name',\n",
              " '_get_no_split_modules',\n",
              " '_get_resized_embeddings',\n",
              " '_get_resized_lm_head',\n",
              " '_get_stopping_criteria',\n",
              " '_greedy_search',\n",
              " '_group_beam_search',\n",
              " '_has_unfinished_sequences',\n",
              " '_hf_peft_config_loaded',\n",
              " '_hook_rss_memory_post_forward',\n",
              " '_hook_rss_memory_pre_forward',\n",
              " '_init_weights',\n",
              " '_initialize_weights',\n",
              " '_is_full_backward_hook',\n",
              " '_is_hf_initialized',\n",
              " '_is_quantized_training_enabled',\n",
              " '_keep_in_fp32_modules',\n",
              " '_keep_in_fp32_modules',\n",
              " '_keys_to_ignore_on_load_missing',\n",
              " '_keys_to_ignore_on_load_unexpected',\n",
              " '_keys_to_ignore_on_save',\n",
              " '_load_from_state_dict',\n",
              " '_load_pretrained_model',\n",
              " '_load_pretrained_model_low_mem',\n",
              " '_load_state_dict_post_hooks',\n",
              " '_load_state_dict_pre_hooks',\n",
              " '_maybe_initialize_input_ids_for_generation',\n",
              " '_maybe_warn_non_full_backward_hook',\n",
              " '_merge_criteria_processor_list',\n",
              " '_modules',\n",
              " '_named_members',\n",
              " '_no_split_modules',\n",
              " '_non_persistent_buffers_set',\n",
              " '_parameters',\n",
              " '_prepare_attention_mask_for_generation',\n",
              " '_prepare_decoder_input_ids_for_generation',\n",
              " '_prepare_encoder_decoder_kwargs_for_generation',\n",
              " '_prepare_generation_config',\n",
              " '_prepare_model_inputs',\n",
              " '_register_load_state_dict_pre_hook',\n",
              " '_register_state_dict_hook',\n",
              " '_reorder_cache',\n",
              " '_replicate_for_data_parallel',\n",
              " '_resize_token_embeddings',\n",
              " '_sample',\n",
              " '_save_to_state_dict',\n",
              " '_set_default_torch_dtype',\n",
              " '_set_gradient_checkpointing',\n",
              " '_skip_keys_device_placement',\n",
              " '_slow_forward',\n",
              " '_state_dict_hooks',\n",
              " '_state_dict_pre_hooks',\n",
              " '_supports_cache_class',\n",
              " '_supports_flash_attn_2',\n",
              " '_supports_sdpa',\n",
              " '_temporary_reorder_cache',\n",
              " '_tie_encoder_decoder_weights',\n",
              " '_tie_or_clone_weights',\n",
              " '_tied_weights_keys',\n",
              " '_update_model_kwargs_for_generation',\n",
              " '_upload_modified_files',\n",
              " '_validate_generated_length',\n",
              " '_validate_model_class',\n",
              " '_validate_model_kwargs',\n",
              " '_version',\n",
              " '_wrapped_call_impl',\n",
              " 'active_adapter',\n",
              " 'active_adapters',\n",
              " 'add_adapter',\n",
              " 'add_memory_hooks',\n",
              " 'add_model_tags',\n",
              " 'add_module',\n",
              " 'apply',\n",
              " 'assisted_decoding',\n",
              " 'base_model',\n",
              " 'base_model_prefix',\n",
              " 'beam_sample',\n",
              " 'beam_search',\n",
              " 'bert',\n",
              " 'bfloat16',\n",
              " 'buffers',\n",
              " 'call_super_init',\n",
              " 'can_generate',\n",
              " 'children',\n",
              " 'classifier',\n",
              " 'compile',\n",
              " 'compute_transition_scores',\n",
              " 'config',\n",
              " 'config_class',\n",
              " 'constrained_beam_search',\n",
              " 'contrastive_search',\n",
              " 'cpu',\n",
              " 'create_extended_attention_mask_for_decoder',\n",
              " 'cuda',\n",
              " 'device',\n",
              " 'disable_adapters',\n",
              " 'disable_input_require_grads',\n",
              " 'double',\n",
              " 'dropout',\n",
              " 'dtype',\n",
              " 'dummy_inputs',\n",
              " 'dump_patches',\n",
              " 'enable_adapters',\n",
              " 'enable_input_require_grads',\n",
              " 'estimate_tokens',\n",
              " 'eval',\n",
              " 'extra_repr',\n",
              " 'float',\n",
              " 'floating_point_ops',\n",
              " 'forward',\n",
              " 'framework',\n",
              " 'from_pretrained',\n",
              " 'generate',\n",
              " 'generation_config',\n",
              " 'get_adapter_state_dict',\n",
              " 'get_buffer',\n",
              " 'get_extended_attention_mask',\n",
              " 'get_extra_state',\n",
              " 'get_head_mask',\n",
              " 'get_input_embeddings',\n",
              " 'get_memory_footprint',\n",
              " 'get_output_embeddings',\n",
              " 'get_parameter',\n",
              " 'get_position_embeddings',\n",
              " 'get_submodule',\n",
              " 'gradient_checkpointing_disable',\n",
              " 'gradient_checkpointing_enable',\n",
              " 'greedy_search',\n",
              " 'group_beam_search',\n",
              " 'half',\n",
              " 'init_weights',\n",
              " 'invert_attention_mask',\n",
              " 'ipu',\n",
              " 'is_gradient_checkpointing',\n",
              " 'is_parallelizable',\n",
              " 'load_adapter',\n",
              " 'load_state_dict',\n",
              " 'load_tf_weights',\n",
              " 'main_input_name',\n",
              " 'model_tags',\n",
              " 'modules',\n",
              " 'name_or_path',\n",
              " 'named_buffers',\n",
              " 'named_children',\n",
              " 'named_modules',\n",
              " 'named_parameters',\n",
              " 'num_labels',\n",
              " 'num_parameters',\n",
              " 'parameters',\n",
              " 'post_init',\n",
              " 'prepare_inputs_for_generation',\n",
              " 'prune_heads',\n",
              " 'push_to_hub',\n",
              " 'register_backward_hook',\n",
              " 'register_buffer',\n",
              " 'register_for_auto_class',\n",
              " 'register_forward_hook',\n",
              " 'register_forward_pre_hook',\n",
              " 'register_full_backward_hook',\n",
              " 'register_full_backward_pre_hook',\n",
              " 'register_load_state_dict_post_hook',\n",
              " 'register_module',\n",
              " 'register_parameter',\n",
              " 'register_state_dict_pre_hook',\n",
              " 'requires_grad_',\n",
              " 'reset_memory_hooks_state',\n",
              " 'resize_position_embeddings',\n",
              " 'resize_token_embeddings',\n",
              " 'retrieve_modules_from_names',\n",
              " 'reverse_bettertransformer',\n",
              " 'sample',\n",
              " 'save_pretrained',\n",
              " 'set_adapter',\n",
              " 'set_extra_state',\n",
              " 'set_input_embeddings',\n",
              " 'share_memory',\n",
              " 'state_dict',\n",
              " 'supports_gradient_checkpointing',\n",
              " 'tie_weights',\n",
              " 'to',\n",
              " 'to_bettertransformer',\n",
              " 'to_empty',\n",
              " 'train',\n",
              " 'training',\n",
              " 'type',\n",
              " 'warn_if_padding_and_no_attention_mask',\n",
              " 'warnings_issued',\n",
              " 'xpu',\n",
              " 'zero_grad']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
